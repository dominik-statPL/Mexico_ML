{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6492d9d3",
   "metadata": {},
   "source": [
    "### Elementy przygotowania danych do wdrożenia modelu\n",
    "\n",
    "Ten program przeprowadza przez etapy przygotowania opisu tekstowego przy wykorzystaniu funkcjonalności bibliotek Spacy i sklearn.\n",
    "> Nie należy tego programu traktować jako wynywalnego od góry do dołu, ponieważ zawiera on w sobie prezentacje zastosowania różnych podejść, które należy rozważyć w trakcie przygotowywania modelu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e000d82",
   "metadata": {},
   "source": [
    "### Instalacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa022b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ładowanie podstawowych bibliotek \n",
    "\n",
    "import pyodbc # do łączenia się z bazą np. SQL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy # do NLP https://pypi.org/project/spacy/\n",
    "import re # wyrażenia regularne\n",
    "import pickle # https://docs.python.org/3/library/pickle.html\n",
    "import os # do obsługi systemu https://docs.python.org/3/library/os.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322298e",
   "metadata": {},
   "source": [
    "Po instalacji biblioteki spacy potrzebny nam jest dodatkowy moduł obsługujący język polski. \n",
    "<br> Instalujemy go z terminala PyCharm poleceniem: python -m spacy download pl_core_news_sm.\n",
    "> Uwaga: W bibliotece Spacy są trzy moduły do obsługi języka polskiego. \n",
    "<br>     Dokumentacja na stronie : https://spacy.io/models/pl. \n",
    "\n",
    "Moduł, który wybrałem jest wg. dokumentacji najmniejszy i działa jak na moje potrzeby OK. Stąd decyzja ten a nie inny. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fbe7d",
   "metadata": {},
   "source": [
    "### Pobranie danych z servera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328abcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DabrowskiD\\\\PycharmProjects\\\\Jupyter\\\\venv\\\\dokumentacja ML'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4c574",
   "metadata": {},
   "source": [
    "### w poniższym spróbujcie zrobić tak żeby lokalizację zbioru brał automatycznie z wyniku powyższej funkcji ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e562991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brak informacji', 'nie       ', 'tak       '], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zmienna report.descr zawiera opisy nieruchomości wystawionych na sprzedaż\n",
    "# zmienna classification.kitch_class i secure_class to zaklasyfikowane ręcznie informacje\n",
    "a = 'model_df'\n",
    "df=pd.read_pickle(f'C:\\\\Users\\\\DabrowskiD\\\\PycharmProjects\\\\Jupyter\\\\venv\\\\MEBLE_ML\\\\regresja\\\\{a}.pkl')\n",
    "\n",
    "# Przegląd wartości znajdujących się w zmiennej  kitch_class\n",
    "\n",
    "labels = np.unique(df['furniture_class'])\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0d1451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nie       ', 'tak       '], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ponieważ chcemy uzyskac odpowiedź na pytanie czy mieszkanie jest umeblowane to musimy się zastanowić jakie\n",
    "# informacje usunąć. Po zapoznaniu się z wynikami poprzedniego polecenia usuwam rekordy dla następujących warunków:\n",
    "# 'furniture_class' == 'brak informacji'\n",
    "# w ten sposób pozostawiamy tylko te wartości, które niosą konkretną informację odnośnie umeblowania\n",
    "\n",
    "df.drop(df.index[df['furniture_class'] == 'brak informacji'], inplace=True)\n",
    "labels = np.unique(df['furniture_class'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cfcbb4",
   "metadata": {},
   "source": [
    "### Przygotowanie danych\n",
    "Przetwarzając dane w DF niestety jesteśmy ograniczeni jej właściwościami. Uruchamiając polecenie type(df['descr']) można zauwazyc, że w wyniku nie otrzymujemy informacji, że jest to string ale pandas.core.series.Series. I to przy przetwarzaniu nasuwa pewne ograniczenia. Można oczywiście przekonwertować informację zawartą w każdej celi na string i obrabiac dane ale cały proces jest nieefektywny i trwa bardzo długo. Stąd w obróbce danych będziemy wykorzystywać atrybuty serii DF a konkretnie dwa: str i apply w połączeniu z funkcjami lambda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b6a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['descr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a6815",
   "metadata": {},
   "source": [
    "#### Konwersja na małe znaki. \n",
    "W przypadku tych danych wielkość liter nie ma wpływu na klasyfikację."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15739da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     już dostępna kameralna kawalerka z klimatyzac...\n",
       "2     uwaga najem okazjonalny prosimy o kontakt tyl...\n",
       "4    m2 27m2 dąbrowa umeblowane wyposażone bliskość...\n",
       "5     nowoczesne mieszkanie po remoncie oferujemy d...\n",
       "6     oferuję do wynajęcia przepiękne świeżo wyremo...\n",
       "Name: descr, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['descr'] = df['descr'].str.lower()\n",
    "df['descr'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc5fbf",
   "metadata": {},
   "source": [
    "#### Usuwanie zbędnych znaków"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade0c71",
   "metadata": {},
   "source": [
    "Wykorzystamy do tego Regex. \n",
    "> Co prawda dalsze etapy obróbki tekstu pozwalają na czyszczenie ale moim zdaniem, na wstępnym etapie, Regex robi to w sposób bardzie kontrolawany i kompleksowy w procesie ściśle definiowanym przez nas. Stąd ta wstępna obróbka. \n",
    "\n",
    "Usuniemy interpunkcję i inne dziwne znaki, które zostały wprowadzone przez przypadek. \n",
    "> Na marginesie: w regeksie podobno jest jakiś elegancki kod pozwalający uwzględnic polskie znaki ale nie chciało mi się szukać. Stąd prymitywne wymienienie ą, ę itd. jako znaki dodatkowe, które mają zostać w tekście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39611677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['descr'] = df['descr'].apply(lambda x: re.sub(r'[^A-Za-z0-9ąćęłńóśźżĄĆĘŁŃÓŚŹŻ]+',' ', str(x))) \n",
    "## dodatkowo dla chętnych - wyszukać regex do polskich znaków"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b0cf7",
   "metadata": {},
   "source": [
    "#### Tokenizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb1a36",
   "metadata": {},
   "source": [
    "Pamiętajmy o kolejności, warto zrobić tokenizację przed Stop Words. \n",
    "> Podobno NLTK (inna biblioteka) jest lepsza do tokenizacji, ale tu używamy Spacy. \n",
    "\n",
    "SpaCy posiada dużo opcji tokenizacji. \n",
    "> Poniższej celi nie należy wykonywać jeśli mamy zamiar używać CountVectorizer. CountVectorizer nie może bezpośrednio obsłużyć serii list, dlatego pojawia się błąd. Zamiast tego można użyć MultiLabelBinarizer, ale nie ma takiej potrzeby bo CV domyślnie dokonuje tokenizacji tekstu. Ponadto posiada szereg opcji, które ułatwiaja przygotowanie i transformację opisu o czym będzie dalej. \n",
    "\n",
    "Przykład dotyczy wykorzystania spacy do tokenizcji i został utworzony na wypadek gdyby ktoś konieczni chciał oprzeć się tylko o tą bibliotekę prz opracowywaniu tekstu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e315ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ( , już, dostępna, kameralna, kawalerka, z, kl...\n",
       "2    ( , uwaga, najem, okazjonalny, prosimy, o, kon...\n",
       "4    (m2, 27m2, dąbrowa, umeblowane, wyposażone, bl...\n",
       "5    ( , nowoczesne, mieszkanie, po, remoncie, ofer...\n",
       "6    ( , oferuję, do, wynajęcia, przepiękne, świeżo...\n",
       "Name: descr, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.pl import Polish\n",
    "nlp = Polish()\n",
    "# Create a Tokenizer with the default settings for Polish\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.tokenizer\n",
    "df['descr'] =  df['descr'].apply(lambda x: tokenizer(x))\n",
    "df['descr'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef7125",
   "metadata": {},
   "source": [
    "#### Stop Words\n",
    "Czyli słowa, które nic nie wnoszą do opisu (w sensie budowy klasyfikacji), a przy tworzeniu modelu mogą wprowadzać szumy. \n",
    "Najczęściej występują w formie dokumentu tekstowego, w którym są wymienione słowa niepotrzebne z punktu widzenia treści. Oczywiście możemy definiować swój plik ze słowami niechcianymi i do niego się odwoływać. Stop words może byc też krótką listą zdefiniowaną przez nas. W poniższym kodzie odwołuję się do pliku zdefiniowanego w polskim modelu SpaCy. Najpierw ładuję polski model, a następnie przypisuję do zmiennej stopwords standardowy plik z modelu. Słownik ten wykorzystuję równiez w prosty sposób przy obróbce tekstu przez CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96be0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    }
   ],
   "source": [
    "# Przyjrzyjmy sie funkcjonalności funkcji stopwords oraz spsobom modyfikacji listy słów. Przed zapuszczeniem stopwords konieczna\n",
    "# jest np. tokenizacja która zmienia string w listę. Inaczej będą ciekawe efekty zapuszczenia stopwords.  \n",
    "\n",
    "# z biblioteki Spacy łaldujemy słownik \n",
    "pl=spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "# tu ładujemy słownik stopwordsów do zmiennej stopwords\n",
    "stopwords = pl.Defaults.stop_words\n",
    "\n",
    "# testujemy typ zmiennej \n",
    "print(type(stopwords))\n",
    "\n",
    "# typ zmiennej to Set. Wykorzystamy więc metody związane z Set-ami do zarządzania i modyfikacji listy wyrażeń do przetwarzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be79d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'byly', 'się', 'im', 'według', 'około', 'ach', 'cokolwiek', 'to', 'moja', 'ktorym', 'mnie', 'ten', 'my', 'sobą', 'twoim', 'tam', 'mają', 'która', 'ktorych', 'teraz', 'albo', 'jesli', 'przede', 'jest', 'być', 'az', 'trzeba', 'nim', 'raz', 'od', 'nasi', 'nam', 'jedno', 'i', 'juz', 'ono', 'już', 'duzo', 'skąd', 'sama', 'toteż', 'w', 'wasze', 'ix', 'totez', 'dwaj', 'gdzie', 'będę', 'na', 'on', 'xii', 'dużo', 'nas', 'jakoś', 'powinni', 'zadna', 'coś', 'tzw', 'kims', 'niemu', 'dwoje', 'takie', 'bede', 'cała', 'vii', 'były', 'jakiz', 'którym', 'taki', 'jednym', 'który', 'może', 'był', 'naszego', 'kto', 'niż', 'viii', 'ktory', 'dosc', 'nasz', 'byc', 'inna', 'one', 'znowu', 'że', 'ich', 'o', 'innych', 'nami', 'znów', 'zadne', 'jednakże', 'go', 'było', 'miał', 'wszystkie', 'cały', 'swoje', 'nich', 'niego', 'chce', 'poniewaz', 'takze', 'ktorzy', 'ktoś', 'nad', 'nic', 'jakas', 'taka', 'dlatego', 'także', 'ci', 'zawsze', 'takich', 'jestem', 'wtedy', 'poza', 'acz', 'jaki', 'mało', 'wszystko', 'sie', 'można', 'przy', 'mimo', 'nie', 'są', 'jeszcze', 'xv', 'za', 'jakby', 'ktokolwiek', 'twoja', 'dwa', 'iz', 'lub', 'czasami', 'ponieważ', 'jakiś', 'dokad', 'twym', 'rowniez', 'oni', 'pod', 'ależ', 'vi', 'była', 'jego', 'aczkolwiek', 'często', 'inny', 'z', 'ją', 'więc', 'nią', 'jedna', 'sposob', 'zaden', 'tobie', 'której', 'ktora', 'zostal', 'moje', 'coraz', 'we', 'dwie', 'cos', 'powinien', 'jakie', 'dokąd', 'mam', 'niz', 'aby', 'ze', 'godz', 'je', 'został', 'sobie', 'bardzo', 'wszyscy', 'sam', 'ku', 'oraz', 'tej', 'przecież', 'ile', 'jezeli', 'no', 'tobą', 'wy', 'bowiem', 'pana', 'kimś', 'tych', 'ktorego', 'inne', 'żeby', 'byl', 'jemu', 'twoje', 'możliwe', 'wiele', 'u', 'moi', 'by', 'bylo', 'dlaczego', 'wszystkim', 'wlasnie', 'twoj', 'toba', 'a', 'nimi', 'pani', 'żadne', 'czasem', 'tutaj', 'jakichs', 'zapewne', 'wasz', 'ja', 'ktorej', 'ty', 'oto', 'które', 'zeby', 'roku', 'bedzie', 'podczas', 'do', 'alez', 'mój', 'nasza', 'jakichś', 'jej', 'xi', 'gdyz', 'lecz', 'cie', 'kilku', 'caly', 'nasze', 'cala', 'bo', 'mogą', 'którzy', 'znow', 'mu', 'byli', 'mna', 'gdyż', 'twoi', 'jakkolwiek', 'moga', 'choć', 'xiv', 'cię', 'tę', 'beda', 'gdyby', 'tys', 'nia', 'gdzies', 'jeden', 'kierunku', 'daleko', 'aż', 'nigdy', 'cali', 'moj', 'bym', 'którego', 'kilka', 'miedzy', 'ta', 'dziś', 'prawie', 'tel', 'ale', 'aj', 'ma', 'również', 'tak', 'kiedy', 'co', 'dzisiaj', 'mną', 'ciebie', 'musi', 'mi', 'bynajmniej', 'zaś', 'jeśli', 'xiii', 'też', 'pomimo', 'natomiast', 'jakis', 'ponad', 'skad', 'wam', 'dla', 'temu', 'między', 'żadnych', 'sposób', 'twój', 'ktore', 'każdy', 'tu', 'żadna', 'wasi', 'te', 'ona', 'po', 'tylko', 'jeżeli', 'tego', 'mamy', 'czemu', 'ok', 'czy', 'moim', 'nawet', 'żaden', 'gdziekolwiek', 'mozliwe', 'naszych', 'dzis', 'iv', 'moze', 'powinna', 'przez', 'jednakze', 'jak', 'bez', 'wszystkich', 'wami', 'właśnie', 'których', 'mozna', 'dobrze', 'jakos', 'jako', 'wielu', 'byla', 'ktos', 'totobą', 'przed', 'jednak', 'iż', 'soba', 'obok', 'czyli', 'gdy', 'zadnych', 'gdzieś', 'przedtem', 'kazdy', 'natychmiast', 'tym', 'ani', 'wśród', 'przeciez', 'będzie', 'wasza', 'niej', 'wie', 'pan', 'jakiż', 'niech', 'będą', 'bardziej', 'powinno', 'jakaś', 'więcej', 'jedynie', 'razie', 'dość', 'owszem', 'was'}\n"
     ]
    }
   ],
   "source": [
    "# przegląd wyrażeń w zmiennej stopwords\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbdc07fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    }
   ],
   "source": [
    "# liczba wyrażeń w stopwords\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e818427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'byly', 'się', 'tych', 'ktorego', 'im', 'inne', 'według', 'około', 'ach', 'żeby', 'cokolwiek', 'to', 'moja', 'ktorym', 'mnie', 'ten', 'byl', 'jemu', 'my', 'twoje', 'możliwe', 'wiele', 'u', 'moi', 'by', 'sobą', 'twoim', 'bylo', 'dlaczego', 'tam', 'mają', 'wszystkim', 'wlasnie', 'twoj', 'która', 'ktorych', 'teraz', 'toba', 'a', 'albo', 'jesli', 'przede', 'nimi', 'pani', 'jest', 'być', 'żadne', 'czasem', 'az', 'trzeba', 'nim', 'tutaj', 'm2', 'raz', 'od', 'pl', 'nasi', 'nam', 'jakichs', 'zapewne', 'wasz', 'jedno', 'ja', 'ktorej', 'i', 'ty', 'oto', 'nr', 'które', 'zeby', 'juz', 'ono', 'roku', 'bedzie', 'już', 'duzo', 'skąd', 'sama', 'toteż', 'w', 'wasze', 'podczas', 'do', 'alez', 'mój', 'nasza', 'jakichś', 'jej', 'xi', 'ix', 'totez', 'dwaj', 'gdzie', 'gdyz', 'będę', 'lecz', 'na', 'cie', 'on', 'xii', 'kilku', 'dużo', 'caly', 'nas', 'jakoś', 'powinni', 'nasze', 'cala', 'bo', 'mogą', 'zadna', 'którzy', 'coś', 'znow', 'tzw', 'mu', 'byli', 'kims', 'mna', 'gdyż', 'twoi', 'niemu', 'dwoje', 'takie', 'jakkolwiek', 'moga', 'bede', 'cała', 'choć', 'vii', 'xiv', 'były', 'cię', 'tę', 'jakiz', 'beda', 'gdyby', 'którym', 'taki', 'tys', 'jednym', 'który', 'nia', 'gdzies', 'może', 'był', 'naszego', 'kto', 'jeden', 'niż', 'viii', 'kierunku', 'daleko', 'aż', 'nigdy', 'ktory', 'dosc', 'nasz', 'byc', 'inna', 'cali', 'one', 'znowu', 'moj', 'że', 'bym', 'ich', 'którego', 'kilka', 'o', 'miedzy', 'innych', 'ta', 'dziś', 'prawie', 'nami', 'znów', 'tel', 'zadne', 'ale', 'aj', 'ma', 'również', 'jednakże', 'go', 'tak', 'kiedy', 'było', 'co', 'miał', 'dzisiaj', 'mną', 'wszystkie', 'ciebie', 'musi', 'cały', 'swoje', 'nich', 'mi', 'bynajmniej', 'zaś', 'niego', 'jeśli', 'chce', 'xiii', 'też', 'the', 'poniewaz', 'pomimo', 'natomiast', 'takze', 'ktorzy', 'jakis', 'ponad', 'skad', 'wam', 'dla', 'zapraszam', 'ktoś', 'nad', 'nic', 'zł', 'jakas', 'taka', 'temu', 'między', 'dlatego', 'żadnych', 'także', 'sposób', 'twój', 'ci', 'zawsze', 'ktore', 'takich', 'jestem', 'wtedy', 'każdy', 'tu', 'żadna', 'poza', 'acz', 'jaki', 'mało', 'wszystko', 'wasi', 'sie', 'te', 'ona', 'po', 'można', 'przy', 'tylko', 'mimo', 'jeżeli', 'nie', 'są', 'tego', 'mamy', 'jeszcze', 'czemu', 'ok', 'xv', 'czy', 'moim', 'za', 'jakby', 'nawet', 'ktokolwiek', 'twoja', 'żaden', 'dwa', 'iz', 'gdziekolwiek', 'mozliwe', 'naszych', 'lub', 'dzis', 'iv', 'moze', 'powinna', 'czasami', 'ponieważ', 'przez', 'jednakze', 'jak', 'jakiś', 'dokad', 'bez', 'twym', 'rowniez', 'oni', 'pod', 'wszystkich', 'wami', 'właśnie', 'których', 'ależ', 'vi', 'była', 'mozna', 'jego', 'dobrze', 'aczkolwiek', 'jakos', 'często', 'inny', 'jako', 'wielu', 'z', 'kimś', 'byla', 'ją', 'więc', 'nią', 'ktos', 'jedna', 'sposob', 'zaden', 'tobie', 'której', 'ktora', 'zostal', 'moje', 'coraz', 'totobą', 'we', 'przed', 'jednak', 'iż', 'dwie', 'cos', 'soba', 'powinien', 'obok', 'jakie', 'dokąd', 'mam', 'niz', 'czyli', 'gdy', 'aby', 'ze', 'zadnych', 'godz', 'gdzieś', 'je', 'przedtem', 'został', 'sobie', 'kazdy', 'bardzo', 'natychmiast', 'tym', 'ani', 'wszyscy', 'wśród', 'przeciez', 'będzie', 'wasza', 'niej', 'sam', 'ku', 'oraz', 'wie', 'pan', 'jakiż', 'niech', 'będą', 'bardziej', 'powinno', 'tej', 'jakaś', 'przecież', 'więcej', 'jedynie', 'razie', 'ile', 'jezeli', 'no', 'dość', 'tobą', 'wy', 'owszem', 'bowiem', 'pana', 'was'}\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "# dodawanie wyrażeń do pierwotnego zestawienia tj. tych które chcemy usunąć np. z opisu. \n",
    "# Wyrazy z Bag_of_words uzyskane w dalszej części kodu\n",
    "\n",
    "stop2 = {'m2', 'pl', 'zł', 'zapraszam', 'the', 'nr',}\n",
    "stopwords = stopwords.union(stop2)\n",
    "lista = list(stopwords)\n",
    "\n",
    "print(stopwords)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41854f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'byly', 'się', 'tych', 'ktorego', 'im', 'inne', 'według', 'około', 'ach', 'żeby', 'cokolwiek', 'to', 'moja', 'ktorym', 'mnie', 'ten', 'byl', 'jemu', 'my', 'twoje', 'możliwe', 'wiele', 'u', 'moi', 'by', 'sobą', 'twoim', 'bylo', 'dlaczego', 'tam', 'mają', 'wszystkim', 'wlasnie', 'twoj', 'która', 'ktorych', 'teraz', 'toba', 'a', 'albo', 'jesli', 'przede', 'nimi', 'pani', 'jest', 'być', 'żadne', 'czasem', 'az', 'trzeba', 'nim', 'tutaj', 'm2', 'raz', 'od', 'pl', 'nasi', 'nam', 'jakichs', 'zapewne', 'wasz', 'jedno', 'ja', 'ktorej', 'i', 'ty', 'oto', 'nr', 'które', 'zeby', 'juz', 'ono', 'roku', 'bedzie', 'już', 'duzo', 'skąd', 'sama', 'toteż', 'w', 'wasze', 'podczas', 'do', 'alez', 'mój', 'nasza', 'jakichś', 'jej', 'xi', 'ix', 'totez', 'dwaj', 'gdzie', 'gdyz', 'będę', 'lecz', 'na', 'cie', 'on', 'xii', 'kilku', 'dużo', 'caly', 'nas', 'jakoś', 'powinni', 'nasze', 'cala', 'bo', 'mogą', 'zadna', 'którzy', 'coś', 'znow', 'tzw', 'mu', 'byli', 'kims', 'mna', 'gdyż', 'twoi', 'niemu', 'dwoje', 'takie', 'jakkolwiek', 'moga', 'bede', 'cała', 'choć', 'vii', 'xiv', 'były', 'cię', 'tę', 'jakiz', 'beda', 'gdyby', 'którym', 'taki', 'tys', 'jednym', 'który', 'nia', 'gdzies', 'może', 'był', 'naszego', 'kto', 'jeden', 'niż', 'viii', 'kierunku', 'daleko', 'aż', 'nigdy', 'ktory', 'dosc', 'nasz', 'byc', 'inna', 'cali', 'one', 'znowu', 'moj', 'że', 'bym', 'ich', 'którego', 'kilka', 'o', 'miedzy', 'innych', 'ta', 'dziś', 'prawie', 'nami', 'znów', 'tel', 'zadne', 'ale', 'aj', 'ma', 'również', 'jednakże', 'go', 'tak', 'kiedy', 'co', 'miał', 'dzisiaj', 'mną', 'wszystkie', 'ciebie', 'musi', 'cały', 'nich', 'mi', 'bynajmniej', 'zaś', 'niego', 'jeśli', 'chce', 'xiii', 'też', 'the', 'poniewaz', 'pomimo', 'natomiast', 'takze', 'ktorzy', 'jakis', 'ponad', 'skad', 'wam', 'dla', 'zapraszam', 'ktoś', 'nad', 'nic', 'zł', 'jakas', 'taka', 'temu', 'między', 'dlatego', 'żadnych', 'także', 'sposób', 'twój', 'ci', 'zawsze', 'ktore', 'takich', 'jestem', 'wtedy', 'każdy', 'tu', 'żadna', 'poza', 'acz', 'jaki', 'mało', 'wszystko', 'wasi', 'sie', 'te', 'ona', 'po', 'można', 'przy', 'tylko', 'mimo', 'jeżeli', 'nie', 'są', 'tego', 'mamy', 'jeszcze', 'czemu', 'ok', 'xv', 'czy', 'moim', 'za', 'jakby', 'nawet', 'ktokolwiek', 'twoja', 'żaden', 'dwa', 'gdziekolwiek', 'mozliwe', 'naszych', 'lub', 'dzis', 'iv', 'moze', 'powinna', 'czasami', 'ponieważ', 'przez', 'jednakze', 'jak', 'jakiś', 'dokad', 'bez', 'twym', 'rowniez', 'oni', 'pod', 'wszystkich', 'wami', 'właśnie', 'których', 'ależ', 'vi', 'była', 'mozna', 'jego', 'dobrze', 'aczkolwiek', 'jakos', 'inny', 'jako', 'wielu', 'z', 'kimś', 'byla', 'ją', 'więc', 'nią', 'ktos', 'jedna', 'sposob', 'zaden', 'tobie', 'której', 'ktora', 'zostal', 'moje', 'coraz', 'totobą', 'we', 'przed', 'jednak', 'iż', 'dwie', 'cos', 'soba', 'powinien', 'obok', 'jakie', 'dokąd', 'mam', 'niz', 'czyli', 'gdy', 'aby', 'ze', 'zadnych', 'gdzieś', 'je', 'przedtem', 'został', 'sobie', 'kazdy', 'bardzo', 'natychmiast', 'tym', 'ani', 'wszyscy', 'wśród', 'przeciez', 'będzie', 'wasza', 'niej', 'sam', 'ku', 'oraz', 'wie', 'pan', 'jakiż', 'niech', 'będą', 'bardziej', 'powinno', 'tej', 'jakaś', 'przecież', 'więcej', 'jedynie', 'razie', 'ile', 'jezeli', 'no', 'dość', 'tobą', 'wy', 'owszem', 'bowiem', 'pana', 'was'}\n",
      "382\n"
     ]
    }
   ],
   "source": [
    "# odejmowanie wyrażeń z pierwotnego zestawienia tj. tych wyrażeń których nie chcemy usunąć np z opisu. Tu odejme  pięć \n",
    "stop2 = {'iz', 'swoje', 'było', 'często', 'godz'}\n",
    "stopwords = stopwords.difference(stop2)\n",
    "\n",
    "print(stopwords)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d6544",
   "metadata": {},
   "source": [
    "#### Zastosowanie wbudowanych funkcji CountVectorizer() do odcięcia mało licznych słów\n",
    "Czasami transformacja i wykorzystanie całego słownictwa zawartego w opisie nie jest efektywne, ponieważ dane mogą zawierać  wyjątkowo rzadkie lub niechciane słowa, które przekazane do TfidfVectorizer().fit() dodadzą w przyszłości niechciane wymiary do danych wejściowych. \n",
    " \n",
    " Jedną z technik stosowanych w tym przypadku byłoby na przykład wydrukowanie częstotliwości słów w dokumentach, \n",
    " a następnie ustawienie dla nich określonego progu. \n",
    " \n",
    " Przykładowa analiza: wyobraźmy sobie, że ustawiliśmy próg 100, a korpus opisu danych składa się z 10000 słów. \n",
    " Po przyjrzeniu się częstotliwości słów, 20 słów pojawia się mniej niż 100 razy. \n",
    " To zbyt często aby te słowa usunąć. Ustawiamy max_features=200 i analizujemy wyniki. Po dobraniu odpowiedniej liczby  przy \n",
    " max_features, gdy najniższa liczba wystąpień słów spadnie do akceptowalnych wyników można zaczynać. Liczba ta oczywiście jest\n",
    " zależna od wielkości zbioru uczącego i samego korpusu.\n",
    " Jeśli parametr max_features jest ustawiony na Brak, podczas transformacji TF-IDF uwzględniany jest cały opis.\n",
    " Tu wykorzystam tą funkcję w inny sposób. Ustawię max_features=100 i będę analizował wystąpienia słów, a ewidentnie zbędne dodam do StopWords. Przeprowadzę jedną iterację w celu demonstracji. Iteracje można powtarzać oczywiście w celu lepszego przygotowania zbioru \n",
    "\n",
    " Jednakże przed wykorzystaniem możliwości CountVectorizer wykorzystamy słownik stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda29cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['48', 'administracyjny', 'agd', 'and', 'aneksem', 'apartament',\n",
       "       'apartment', 'asari', 'asaricrm', 'balkon', 'biur', 'budynek',\n",
       "       'budynku', 'cena', 'centrum', 'com', 'crm', 'cywilnego', 'czynsz',\n",
       "       'dodatkowo', 'dostępne', 'for', 'garażu', 'in', 'informacje', 'is',\n",
       "       'kaucja', 'kodeksu', 'kuchennym', 'kuchni', 'kuchnia', 'lodówka',\n",
       "       'lokalizacja', 'meble', 'media', 'miasta', 'miejsca', 'miejsce',\n",
       "       'mieszkania', 'mieszkanie', 'min', 'możliwość', 'najmu',\n",
       "       'nieruchomości', 'nowe', 'numer', 'of', 'oferta', 'oferty',\n",
       "       'ogrzewanie', 'opłaty', 'osób', 'park', 'pełni', 'piekarnik',\n",
       "       'piętrze', 'pln', 'pobliżu', 'podziemnym', 'pokaż', 'pokojowe',\n",
       "       'pokój', 'postojowe', 'powierzchni', 'pralka', 'prezentację',\n",
       "       'programu', 'przedpokoju', 'przedpokój', 'prąd', 'płyta', 'room',\n",
       "       'rozumieniu', 'salon', 'salonu', 'sklepy', 'składa', 'stanowi',\n",
       "       'sypialni', 'sypialnia', 'szafa', 'ul', 'umeblowane', 'wc', 'wg',\n",
       "       'with', 'woda', 'wynajem', 'wynajęcia', 'wyposażona', 'wyposażone',\n",
       "       'wysłana', 'zabudowie', 'zaraz', 'zmywarka', 'znajduje', 'zużycia',\n",
       "       'łazienka', 'łazienki', 'łóżko'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=100, stop_words=lista)\n",
    "wektor = vectorizer.fit_transform(df['descr'])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0845659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=100,\n",
       "                stop_words=[&#x27;byly&#x27;, &#x27;się&#x27;, &#x27;tych&#x27;, &#x27;ktorego&#x27;, &#x27;im&#x27;, &#x27;inne&#x27;,\n",
       "                            &#x27;według&#x27;, &#x27;około&#x27;, &#x27;ach&#x27;, &#x27;żeby&#x27;, &#x27;cokolwiek&#x27;, &#x27;to&#x27;,\n",
       "                            &#x27;moja&#x27;, &#x27;ktorym&#x27;, &#x27;mnie&#x27;, &#x27;ten&#x27;, &#x27;byl&#x27;, &#x27;jemu&#x27;,\n",
       "                            &#x27;my&#x27;, &#x27;twoje&#x27;, &#x27;możliwe&#x27;, &#x27;wiele&#x27;, &#x27;u&#x27;, &#x27;moi&#x27;, &#x27;by&#x27;,\n",
       "                            &#x27;sobą&#x27;, &#x27;twoim&#x27;, &#x27;bylo&#x27;, &#x27;dlaczego&#x27;, &#x27;tam&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=100,\n",
       "                stop_words=[&#x27;byly&#x27;, &#x27;się&#x27;, &#x27;tych&#x27;, &#x27;ktorego&#x27;, &#x27;im&#x27;, &#x27;inne&#x27;,\n",
       "                            &#x27;według&#x27;, &#x27;około&#x27;, &#x27;ach&#x27;, &#x27;żeby&#x27;, &#x27;cokolwiek&#x27;, &#x27;to&#x27;,\n",
       "                            &#x27;moja&#x27;, &#x27;ktorym&#x27;, &#x27;mnie&#x27;, &#x27;ten&#x27;, &#x27;byl&#x27;, &#x27;jemu&#x27;,\n",
       "                            &#x27;my&#x27;, &#x27;twoje&#x27;, &#x27;możliwe&#x27;, &#x27;wiele&#x27;, &#x27;u&#x27;, &#x27;moi&#x27;, &#x27;by&#x27;,\n",
       "                            &#x27;sobą&#x27;, &#x27;twoim&#x27;, &#x27;bylo&#x27;, &#x27;dlaczego&#x27;, &#x27;tam&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_features=100,\n",
       "                stop_words=['byly', 'się', 'tych', 'ktorego', 'im', 'inne',\n",
       "                            'według', 'około', 'ach', 'żeby', 'cokolwiek', 'to',\n",
       "                            'moja', 'ktorym', 'mnie', 'ten', 'byl', 'jemu',\n",
       "                            'my', 'twoje', 'możliwe', 'wiele', 'u', 'moi', 'by',\n",
       "                            'sobą', 'twoim', 'bylo', 'dlaczego', 'tam', ...])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Jeśli użyliśmy tokenizacji to:\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# count_vec = MultiLabelBinarizer()\n",
    "# mlb = count_vec.fit(df['descr'])\n",
    "# pd.DataFrame(mlb.transform(dfdf['descr']), columns=[mlb.classes_])\n",
    "\n",
    "X=df['descr'] # tu generuje wektor opisów do analizy\n",
    "count_v = CountVectorizer(max_features=100, stop_words=lista)\n",
    "count_v.fit(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd22ad",
   "metadata": {},
   "source": [
    "#### Zastosowanie innego podejścia do wybrania mało licznych słów.\n",
    "W celi poniżej alternatywna analiza występowania słów w opisie. Zliczamy wystąpienia słów w opisach\n",
    "bag_of_words macierz, w której każdy wiersz reprezentuje określony tekst, a każda kolumna reprezentuje słowo w słowniku, czyli wszystkie słowa znalezione w korpusie. Czyli bag_of_words[i,j] to wystąpienie słowa j w tekście i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfd8b007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mieszkanie', 16082), ('nieruchomości', 8266), ('czynsz', 6243), ('numer', 6049), ('48', 5866), ('najmu', 5769), ('pokaż', 5665), ('and', 5474), ('znajduje', 5055), ('mieszkania', 5018), ('in', 4910), ('pln', 4594), ('oferty', 4459), ('centrum', 4453), ('of', 4393), ('budynku', 4215), ('łazienka', 4170), ('wynajęcia', 4049), ('ul', 4023), ('with', 3926), ('miejsce', 3898), ('kaucja', 3767), ('oferta', 3752), ('prąd', 3635), ('sypialni', 3542), ('lokalizacja', 3440), ('piętrze', 3422), ('ogrzewanie', 3394), ('łazienki', 3369), ('opłaty', 3289), ('składa', 3126), ('powierzchni', 3078), ('balkon', 3064), ('kuchnia', 3000), ('aneksem', 2999), ('pełni', 2985), ('apartment', 2981), ('salon', 2960), ('kuchennym', 2929), ('apartament', 2893), ('wc', 2750), ('is', 2736), ('wyposażone', 2700), ('sypialnia', 2669), ('rozumieniu', 2644), ('kuchni', 2621), ('umeblowane', 2609), ('piekarnik', 2584), ('salonu', 2567), ('woda', 2527), ('stanowi', 2493), ('lodówka', 2434), ('kodeksu', 2433), ('pobliżu', 2426), ('cywilnego', 2416), ('agd', 2360), ('szafa', 2357), ('miasta', 2318), ('przedpokoju', 2314), ('pralka', 2281), ('administracyjny', 2275), ('for', 2223), ('com', 2219), ('zmywarka', 2154), ('wysłana', 2123), ('dodatkowo', 2111), ('możliwość', 2111), ('sklepy', 2099), ('meble', 2087), ('pokój', 2084), ('park', 2066), ('płyta', 2011), ('programu', 1968), ('biur', 1962), ('media', 1942), ('garażu', 1930), ('zużycia', 1926), ('miejsca', 1911), ('budynek', 1901), ('zabudowie', 1894), ('nowe', 1888), ('cena', 1858), ('informacje', 1857), ('pokojowe', 1852), ('room', 1852), ('postojowe', 1833), ('wyposażona', 1823), ('osób', 1790), ('wynajem', 1742), ('łóżko', 1740), ('asari', 1719), ('crm', 1718), ('wg', 1718), ('podziemnym', 1717), ('asaricrm', 1716), ('zaraz', 1704), ('dostępne', 1685), ('prezentację', 1668), ('min', 1661), ('przedpokój', 1645)]\n"
     ]
    }
   ],
   "source": [
    "## można zrobić też w jednym kroku fit_transform\n",
    "bag_of_words = count_v.transform(X)\n",
    "suma_slow = bag_of_words.sum(axis=0) # suma_slow to wektor, który zawiera sumę wystąpień każdego słowa we wszystkich tekstach \n",
    "# print(suma_slow) # tu jak ktoś ciekawy ja to wygląda pierwotnie\n",
    "\n",
    "# Zliczanie wystąpień. W pierwszej linijce pętla zliczająca liczbę wystąpień i zwracająca parę: słowo - liczba wystąpień.\n",
    "# W drugiej linijce sortowanie słów od największej liczby wystąpień do najmiejszej\n",
    "\n",
    "words_freq = [(word, suma_slow[0, idx]) for word, idx in count_v.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(words_freq) # drukowanie i analiza\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8065f9",
   "metadata": {},
   "source": [
    "#### Zastosowanie słownika predefiniowanego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afcb01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mieszkanie', 16082), ('meble', 2087), ('kanapa', 810)]\n"
     ]
    }
   ],
   "source": [
    "# z zastosowaniem słownika\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "slownik = ['mieszkanie', 'meble', 'kanapa']\n",
    "\n",
    "X=df['descr'] # tu generuje wektor opisów do analizy\n",
    "count_v = CountVectorizer(max_features=100, stop_words=lista, vocabulary = slownik)\n",
    "\n",
    "bag_of_words = count_v.fit_transform(X)\n",
    "suma_slow = bag_of_words.sum(axis=0)\n",
    "\n",
    "words_freq = [(word, suma_slow[0, idx]) for word, idx in count_v.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(words_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5846e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to jest zestaw wyrazeń, które chcę dodać do stop words po analizie\n",
    "stop2 = {'m2', 'pl', 'zł', 'zapraszam', 'the', 'nr',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb08998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ciekawostka: są dodatkowe opcje CountVectorizer. Możemy ustalić np. minimalną liczbę wystąpień poleceniem min_df \n",
    "# żeby je usunąć i zmiejszyć liczbę wymiarów\n",
    "# coun_vect = CountVectorizer(min_df=10) # ustawienie limitu na 10\n",
    "# count_matrix = coun_vect.fit_transform(test_x)\n",
    "# count_array = count_matrix.toarray() \n",
    "# df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names()) # tu pozyskujemy listę słów\n",
    "# print(df) # tu drukujemy te słowa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04f118",
   "metadata": {},
   "source": [
    "### Zastosowanie funkcji n-gram\n",
    "Niektóre określenia mają większy sens gdy rozpatrujemy je jako całość, a nie jako osobne słowa.\n",
    "<br> Dotyczy np. określeń: aneks kuchenny.\n",
    "<br> Dlatego możemy stosować n-gramy w celu utworzenia zestawień słów umiejscowionych koło siebie w analizowanym tekście.\n",
    "\n",
    "Implementacja w CountVectorizer przebiega prosto. W opcjach dodajemy parametr ngram_range=\n",
    "Gdzie wartość range określa jakie n-gramy mają być zastosowane.\n",
    "ngram_range=(1,2) dobierze każde słowo z osobna i wszystkie pary słów\n",
    "ngram_range=(2,2) dobierze tylko pary słów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a9c21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['48 pokaż', 'aneks kuchenny', 'aneksem kuchennym', 'apartment is',\n",
       "       'art 66', 'asari crm', 'asaricrm com', 'biur nieruchomości',\n",
       "       'biuro nieruchomości', 'cena najmu', 'centrum miasta',\n",
       "       'charakter informacyjny', 'ciepła woda', 'crm asaricrm',\n",
       "       'czynsz administracyjny', 'czynsz najmu', 'dodatkowe informacje',\n",
       "       'dostępne zaraz', 'duży balkon', 'dwupokojowe mieszkanie',\n",
       "       'garażu podziemnym', 'hali garażowej', 'handlowej rozumieniu',\n",
       "       'is located', 'istnieje możliwość', 'kabina prysznicowa',\n",
       "       'kaucja zwrotna', 'kodeksu cywilnego', 'komunikacji miejskiej',\n",
       "       'komórka lokatorska', 'kuchennym sypialni', 'liczne sklepy',\n",
       "       'living room', 'miejsce parkingowe', 'miejsce postojowe',\n",
       "       'mieszkania przynależy', 'mieszkanie dostępne', 'mieszkanie pełni',\n",
       "       'mieszkanie pokojowe', 'mieszkanie powierzchni',\n",
       "       'mieszkanie składa', 'mieszkanie znajduje', 'możliwość wynajęcia',\n",
       "       'najem okazjonalny', 'najmu okazjonalnego', 'nieruchomości asari',\n",
       "       'niniejsze ogłoszenie', 'niniejszego ogłoszenia', 'numer 48',\n",
       "       'odpowiedzialny zawodowo', 'oferta wysłana', 'oferty handlowej',\n",
       "       'oferty rozumieniu', 'ogrzewanie miejskie', 'ogłoszenia stanowi',\n",
       "       'opłaty czynsz', 'pełni umeblowane', 'pełni wyposażone',\n",
       "       'piekarnik płyta', 'pln czynsz', 'pokaż numer',\n",
       "       'pokojowe mieszkanie', 'postojowe garażu',\n",
       "       'pośrednik odpowiedzialny', 'programu biur', 'przepisów kodeksu',\n",
       "       'przynależy miejsce', 'przystanek autobusowy', 'prąd gaz',\n",
       "       'prąd wg', 'punkty usługowe', 'płyta indukcyjna', 'real estate',\n",
       "       'room with', 'rozumieniu art', 'rozumieniu kodeksu',\n",
       "       'rozumieniu przepisów', 'salon aneksem', 'salonu aneksem',\n",
       "       'składa salonu', 'sprzęt agd', 'stanowi oferty', 'stolik kawowy',\n",
       "       'stół krzesłami', 'sypialni łazienki', 'treść niniejszego',\n",
       "       'umeblowane wyposażone', 'umowa najmu', 'umowy pośrednictwa',\n",
       "       'wg zużycia', 'wyjściem balkon', 'wykonanie umowy',\n",
       "       'wymagana kaucja', 'wynajęcia mieszkanie', 'wysokim standardzie',\n",
       "       'wysłana programu', 'zawodowo wykonanie', 'znajduje piętrze',\n",
       "       'łazienka wc', 'łazienki wc'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=100, ngram_range=(2,2), stop_words=lista)\n",
    "# Map each word in our training narratives to a vector position\n",
    "vectorizer.fit(df['descr'])\n",
    "\n",
    "# tu otrzymana lista ngramów\n",
    "vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f905d3",
   "metadata": {},
   "source": [
    "### Wdrożenie ograniczonego modelu. \n",
    "> Ten model nie jest efektywny bo analiza i korekta opisu jest przeprowadzona w celach demonstracyjnych i prezentuje funkcjonalność narzędzi. \n",
    "<br> Prezentuje również efektywność takiego podejścia. Poprzez likwidację wymiarów osiągamy znaczne oszczędności czasowe związane z wdrożeniem modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "40085557",
   "metadata": {},
   "outputs": [],
   "source": [
    "## jeżeli to wszystko co jest w komórkach poniżej jest tym samym co w ML lub Bayessowski, to usuńmy to.\n",
    "## ten dokument może pozostać tylko opisem sposobów wyboru stop wordsów i przygotowania tekstu do realizacji autoklasyfikacji.\n",
    "# Tu po analizie próba znalezienia parametrów\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1200,  stop_words=lista)\n",
    "# Map each word in our training narratives to a vector position\n",
    "vectorizer.fit(df['descr'])\n",
    "# Convert each training narrative to its vector representation and stack them into a matrix\n",
    "X = vectorizer.transform(df['descr'])\n",
    "X = X.toarray()\n",
    "y = df['kitch_class']\n",
    "\n",
    "# podział zbioru na 3 części. W pierwszym kroku otrzymamy 2 zbiory - uszący i treningowy z walidacyjnym. W 2 kroku dokonujemy \n",
    "# podziału zbioru testowo - walidacyjnego na dwa odrębne zbiory testowy i walidacyjny\n",
    "\n",
    "X_train, X_test_all, y_train, y_test_all = train_test_split(X, y, test_size=0.50, random_state=2)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_all, y_test_all, test_size=0.50, random_state=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "54563c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of values for C are [1.00000000e-03 1.58489319e-03 2.51188643e-03 3.98107171e-03\n",
      " 6.30957344e-03 1.00000000e-02 1.58489319e-02 2.51188643e-02\n",
      " 3.98107171e-02 6.30957344e-02 1.00000000e-01 1.58489319e-01\n",
      " 2.51188643e-01 3.98107171e-01 6.30957344e-01 1.00000000e+00\n",
      " 1.58489319e+00 2.51188643e+00 3.98107171e+00 6.30957344e+00\n",
      " 1.00000000e+01 1.58489319e+01 2.51188643e+01 3.98107171e+01\n",
      " 6.30957344e+01 1.00000000e+02 1.58489319e+02 2.51188643e+02\n",
      " 3.98107171e+02 6.30957344e+02 1.00000000e+03]\n",
      "The list of values for gamma are [1.00000000e-03 1.58489319e-03 2.51188643e-03 3.98107171e-03\n",
      " 6.30957344e-03 1.00000000e-02 1.58489319e-02 2.51188643e-02\n",
      " 3.98107171e-02 6.30957344e-02 1.00000000e-01 1.58489319e-01\n",
      " 2.51188643e-01 3.98107171e-01 6.30957344e-01 1.00000000e+00\n",
      " 1.58489319e+00 2.51188643e+00 3.98107171e+00 6.30957344e+00\n",
      " 1.00000000e+01 1.58489319e+01 2.51188643e+01 3.98107171e+01\n",
      " 6.30957344e+01 1.00000000e+02 1.58489319e+02 2.51188643e+02\n",
      " 3.98107171e+02 6.30957344e+02 1.00000000e+03]\n"
     ]
    }
   ],
   "source": [
    "# Dobór parametrów przy użyciu metody optymizacji Bayessowskiej. Ze względu na demonstracyjny charakter \n",
    "# ograniczę przestrzeń wyszukiwania w celu zaoszczędzenia czasu. Z drugiej strony zawężona przestrzeń poszukiwań pozwala funkcji na lepszy wybór parametrów.\n",
    "\n",
    "# Zdefiniowanie przestrzeni poszukiwania\n",
    "\n",
    "# Przestrzeń dla wartości C\n",
    "C_range = np.logspace(-3, 3, 31) # pierwsza wartość, wartość końcowa, ilość wystąpień np.-5, 5, 21\n",
    "print(f'The list of values for C are {C_range}')\n",
    "\n",
    "# Przestrzeń dla wartości gamma\n",
    "gamma_range = np.logspace(-3, 3, 31) # pierwsza wartość, wartość końcowa, ilość wystąpień np.-5, 5, 21\n",
    "print(f'The list of values for gamma are {gamma_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "63531e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:43<00:00,  2.83s/trial, best loss: -0.9191607059755256]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
    "from statistics import mean\n",
    "\n",
    "# Przestrzeń\n",
    "space = {\n",
    "    'C' : hp.choice('C', C_range),\n",
    "    'gamma' : hp.choice('gamma', gamma_range.tolist()+['scale', 'auto']),\n",
    "    'kernel' : hp.choice('kernel', ['linear', 'rbf'])\n",
    "}\n",
    "# W tym kroku użyjemy funkcji StratifiedKFold do podziału zbioru. Funkcja ta powala dokonac losowania stratyfikacyjnego w niezbyt\n",
    "# zrównoważonych zbiorach. Zobaczymy czy zastosowanie tej funkcji pozwoli nam w sposób bardziej dokładny. () \n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Objective function\n",
    "def objective(params):\n",
    "    \n",
    "    svc = SVC(**params)\n",
    "    scores = cross_val_score(svc, X_train, y_train, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "    # Extract the best score\n",
    "    best_score = mean(scores)\n",
    "    # Loss must be minimized\n",
    "    loss = - best_score\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "# Trials to track progress\n",
    "bayes_trials = Trials()\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 100, trials = bayes_trials) # max_eval powinno być wyższe np. 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f534724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 7, 'gamma': 32, 'kernel': 0}\n",
      "{'C': 0.025118864315095808, 'gamma': 'auto', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Print the index of the best parameters\n",
    "print(best)\n",
    "# Print the values of the best parameters\n",
    "print(space_eval(space, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "89598dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       aneks       0.91      0.91      0.91       726\n",
      "     odrębna       0.83      0.84      0.84       393\n",
      "\n",
      "    accuracy                           0.88      1119\n",
      "   macro avg       0.87      0.87      0.87      1119\n",
      "weighted avg       0.88      0.88      0.88      1119\n",
      "\n",
      "0.8838248436103664\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "Bayes_predict_model_SVM = SVC(C=1.0, kernel = 'linear' , gamma=0.001, random_state=42).fit(X_train,y_train)\n",
    "y_pred_test = Bayes_predict_model_SVM.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred_test))\n",
    "print(metrics.accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "123392a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = metrics.confusion_matrix(y_test,y_pred_test), display_labels = ['True', 'False'])\n",
    "cm_display.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
